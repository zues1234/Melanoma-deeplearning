{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install wtfml\n!pip install pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\n\nimport albumentations\nimport pretrainedmodels\n\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\n\nimport cv2\nimport torch\n\nimport numpy as np\n\n\nfrom PIL import Image\nfrom PIL import ImageFile\n\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n#from apex import amp\nfrom sklearn import metrics\nfrom torch.nn import functional as F\n\n#from wtfml.data_loaders.image import ClassificationDataset\n#from wtfml.engine import Engine\nfrom wtfml.utils import EarlyStopping\n\nfrom sklearn.model_selection import StratifiedKFold\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SEResNext50_32x4d(nn.Module):\n    def __init__(self, pretrained=\"imagenet\"):\n        super(SEResNext50_32x4d, self).__init__()\n        self.model = pretrainedmodels.__dict__[\n            \"se_resnext50_32x4d\"\n        ](pretrained=pretrained)\n        self.out = nn.Linear(2048, 1)\n    \n    def forward(self, image, targets):\n        bs, _, _, _ = image.shape\n        x = self.model.features(image)\n        x = F.adaptive_avg_pool2d(x, 1)\n        x = x.reshape(bs, -1)\n        out = self.out(x)\n        loss = nn.BCEWithLogitsLoss()(\n            out, targets.reshape(-1, 1).type_as(out)\n        )\n        return out, loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n\n    def __init__(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport datetime\nimport torch\nfrom tqdm import tqdm\n\ntry:\n    from torch.cuda import amp\n    _amp_available = True\nexcept ImportError:\n    _amp_available = False\n\ntry:\n    import torch_xla.core.xla_model as xm\n    import torch_xla.distributed.parallel_loader as pl\n\n    _xla_available = True\nexcept ImportError:\n    _xla_available = False\n\n\ndef reduce_fn(vals):\n    return sum(vals) / len(vals)\n\n\nclass Engine:\n    def __init__(\n        self,\n        model,\n        optimizer,\n        device,\n        data_loader,\n        scheduler=None,\n        accumulation_steps=1,\n        use_tpu=False,\n        tpu_print=10,\n        fp16=False,\n        model_fn=None,\n        use_mean_loss=False,\n    ):\n        super(Engine, self).__init__()\n        \"\"\"\n        model_fn should take batch of data, device and model and return loss\n        for example:\n            def model_fn(data, device, model):\n                images, targets = data\n                images = list(image.to(device) for image in images)\n                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n                _, loss = model(images, targets)\n                return loss\n        \"\"\"\n        self.model = model\n        self.optimizer = optimizer\n        self.device = device\n        self.scheduler = scheduler\n        self.data_loader = data_loader\n        self.accumulation_steps = accumulation_steps\n        self.use_tpu = use_tpu\n        self.tpu_print = tpu_print\n        self.model_fn = model_fn\n        self.fp16 = fp16\n        if self.fp16 and not _amp_available:\n            raise Exception(\n                \"You want to use fp16 but dont have amp installed\"\n            )\n        self.use_mean_loss = use_mean_loss\n        self.scaler = None\n\n        if self.use_tpu and not _xla_available:\n            raise Exception(\n                \"You want to use TPUs but you dont have pytorch_xla installed\"\n            )\n        if self.fp16 and use_tpu:\n            raise Exception(\"Apex fp16 is not available when using TPUs\")\n        if self.fp16:\n            self.scaler = amp.GradScaler()\n\n    def train(self):\n        losses = AverageMeter()\n        self.model.train()\n        print_idx = int(len(self.data_loader) * self.tpu_print / 100)\n        if self.accumulation_steps > 1:\n            self.optimizer.zero_grad()\n        if self.use_tpu:\n            para_loader = pl.ParallelLoader(self.data_loader, [self.device])\n            tk0 = para_loader.per_device_loader(self.device)\n        else:\n            tk0 = tqdm(self.data_loader, total=len(self.data_loader))\n\n        for b_idx, data in enumerate(tk0):\n            if self.accumulation_steps == 1 and b_idx == 0:\n                self.optimizer.zero_grad()\n\n            if self.model_fn is None:\n                for key, value in data.items():\n                    data[key] = value.to(self.device)\n                _, loss = self.model(**data)\n            else:\n                if self.fp16:\n                    with amp.autocast():\n                        loss = self.model_fn(data, self.device, self.model)\n                else:\n                    loss = self.model_fn(data, self.device, self.model)\n\n            if not self.use_tpu:\n                with torch.set_grad_enabled(True):\n                    if self.use_mean_loss:\n                        loss = loss.mean()\n\n                    if self.fp16:\n                        self.scaler.scale(loss).backward()\n                    else:\n                        loss.backward()\n\n                    if (b_idx + 1) % self.accumulation_steps == 0:\n                        if self.fp16:\n                            self.scaler.step(self.optimizer)\n                        else:\n                            self.optimizer.step()\n\n                        if self.scheduler is not None:\n                            self.scheduler.step(loss)\n\n                        if self.fp16:\n                            self.scaler.update()\n\n                        if b_idx > 0:\n                            self.optimizer.zero_grad()\n\n            else:\n                loss.backward()\n                xm.optimizer_step(self.optimizer)\n                if self.scheduler is not None:\n                    self.scheduler.step(loss)\n                if b_idx > 0:\n                    self.optimizer.zero_grad()\n            if self.use_tpu:\n                reduced_loss = xm.mesh_reduce(\"loss_reduce\", loss, reduce_fn)\n                losses.update(reduced_loss.item(), self.data_loader.batch_size)\n            else:\n                losses.update(loss.item(), self.data_loader.batch_size)\n\n            if not self.use_tpu:\n                tk0.set_postfix(loss=losses.avg)\n            else:\n                if b_idx % print_idx == 0 or b_idx == len(self.data_loader):\n                    xm.master_print(\n                        f\"{datetime.datetime.now()}: Batch {b_idx} / {len(self.data_loader)}, loss={losses.avg}\"\n                    )\n        if not self.use_tpu:\n            tk0.close()\n        return losses.avg\n\n    def evaluate(self, return_predictions=False):\n        losses = AverageMeter()\n        print_idx = int(len(self.data_loader) * self.tpu_print / 100)\n        self.model.eval()\n        final_predictions = []\n        with torch.no_grad():\n            if self.use_tpu:\n                para_loader = pl.ParallelLoader(self.data_loader, [self.device])\n                tk0 = para_loader.per_device_loader(self.device)\n            else:\n                tk0 = tqdm(self.data_loader, total=len(self.data_loader))\n            for b_idx, data in enumerate(tk0):\n                for key, value in data.items():\n                    data[key] = value.to(self.device)\n                if self.fp16:\n                    with amp.autocast():\n                        batch_preds, loss = self.model(**data)\n                else:\n                    batch_preds, loss = self.model(**data)\n                if return_predictions:\n                    final_predictions.append(batch_preds)\n                if self.use_tpu:\n                    reduced_loss = xm.mesh_reduce(\"loss_reduce\", loss, reduce_fn)\n                    losses.update(reduced_loss.item(), self.data_loader.batch_size)\n                else:\n                    if self.use_mean_loss:\n                        loss = loss.mean()\n                    losses.update(loss.item(), self.data_loader.batch_size)\n                if not self.use_tpu:\n                    tk0.set_postfix(loss=losses.avg)\n                else:\n                    if b_idx % print_idx == 0 or b_idx == len(self.data_loader):\n                        xm.master_print(\n                            f\"{datetime.datetime.now()}: Batch {b_idx} / {len(self.data_loader)}, loss={losses.avg}\"\n                        )\n            if not self.use_tpu:\n                tk0.close()\n        return losses.avg, final_predictions\n    \n    def predict(self):\n        self.model.eval()\n        final_predictions = []\n        if self.use_tpu:\n            raise Exception(\"TPU not available for predict yet!\")\n        with torch.no_grad():\n            tk0 = tqdm(self.data_loader, total=len(self.data_loader))\n            for data in tk0:\n                for key, value in data.items():\n                    data[key] = value.to(self.device)\n                predictions, _ = self.model(**data)\n                predictions = predictions.cpu()\n                final_predictions.append(predictions)\n        return final_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassificationDataset:\n    def __init__(self, image_paths, targets, resize, augmentations=None, backend=\"pil\", channel_first=True,):\n        super(ClassificationDataset, self).__init__()\n        \n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n        self.backend = backend\n        self.channel_first = channel_first\n        \n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        targets = self.targets[item]\n        if os.path.isfile(self.image_paths[item]):\n            if self.backend == \"pil\":\n                image = Image.open(self.image_paths[item])\n                if self.resize is not None:\n                    image = image.resize(\n                        (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n                    )\n                image = np.array(image)\n                if self.augmentations is not None:\n                    augmented = self.augmentations(image=image)\n                    image = augmented[\"image\"]\n            elif self.backend == \"cv2\":\n                image = cv2.imread(self.image_paths[item])\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                if self.resize is not None:\n                    image = cv2.resize(\n                        image,\n                        (self.resize[1], self.resize[0]),\n                        interpolation=cv2.INTER_CUBIC,\n                    )\n                if self.augmentations is not None:\n                    augmented = self.augmentations(image=image)\n                image = augmented[\"image\"]\n            else:\n                raise Exception(\"Backend not implemented\")\n            if self.channel_first:\n                image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        return {\n            \"image\": torch.tensor(image),\n            \"targets\": torch.tensor(targets),\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create folds\ndf = pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\ndf[\"kfold\"] = -1    \ndf = df.sample(frac=1).reset_index(drop=True)\ny = df.target.values\nkf = StratifiedKFold(n_splits=5)\n\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n    df.loc[v_, 'kfold'] = f\n\ndf.to_csv(\"train_folds.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"./train_folds.csv\")\ndf.shape\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(fold):\n    training_data_path = \"../input/siic-isic-224x224-images/train\"\n    df = pd.read_csv(\"./train_folds.csv\")\n    device = \"cuda\"\n    epochs = 50\n    train_bs = 32\n    valid_bs = 16\n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225)\n\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n\n    train_aug = albumentations.Compose(\n        [\n            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n        ]\n    )\n\n    valid_aug = albumentations.Compose(\n        [\n            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n        ]\n    )\n\n    train_images = df_train.image_name.values.tolist()\n    train_images = [os.path.join(training_data_path, i + \".png\") for i in train_images]\n    train_targets = df_train.target.values\n\n    valid_images = df_valid.image_name.values.tolist()\n    valid_images = [os.path.join(training_data_path, i + \".png\") for i in valid_images]\n    valid_targets = df_valid.target.values\n\n    train_dataset = ClassificationDataset(\n        image_paths=train_images,\n        targets=train_targets,\n        resize=None,\n        augmentations=train_aug\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=train_bs,\n        shuffle=True,\n        num_workers=4\n    )\n\n    valid_dataset = ClassificationDataset(\n        image_paths=valid_images,\n        targets=valid_targets,\n        resize=None,\n        augmentations=valid_aug,\n    )\n\n    valid_loader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size=valid_bs,\n        shuffle=False,\n        num_workers=4\n    )\n\n    model = SEResNext50_32x4d(pretrained=\"imagenet\")\n    model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        patience=3,\n        mode=\"max\"\n    )\n\n    es = EarlyStopping(patience=5, mode=\"max\")\n    for epoch in range(epochs):\n        training_loss = Engine(model,optimizer,device,train_loader,scheduler=scheduler,fp16=True).train()\n        valid_loss, predictions = Engine(model,optimizer,device,valid_loader,scheduler=scheduler,fp16=True).evaluate(return_predictions=True)\n        predictions = [tensor.detach().cpu().numpy() for tensor in predictions]\n        predictions = np.vstack((predictions)).ravel()\n        auc = metrics.roc_auc_score(valid_targets, predictions)\n        print(f\"Epoch = {epoch}, AUC = {auc}\")\n        scheduler.step(auc)\n\n        es(auc, model, model_path=f\"model_fold_{fold}.bin\")\n        if es.early_stop:\n            print(\"Early stopping\")\n            break\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(fold):\n    test_data_path = \"../input/siic-isic-224x224-images/test\"\n    model_path = f\"model_fold_{fold}.bin\"\n    df_test = pd.read_csv(\"../input/siim-isic-melanoma-classification/test.csv\")\n    df_test.loc[:, \"target\"] = 0\n\n    device = \"cuda\"\n    epochs = 50\n    test_bs = 16\n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225)\n\n    test_aug = albumentations.Compose(\n        [\n            albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n        ]\n    )\n\n    test_images = df_test.image_name.values.tolist()\n    test_images = [os.path.join(test_data_path, i + \".png\") for i in test_images]\n    test_targets = df_test.target.values\n\n    test_dataset = ClassificationDataset(\n        image_paths=test_images,\n        targets=test_targets,\n        resize=None,\n        augmentations=test_aug\n    )\n\n    test_loader = torch.utils.data.DataLoader(\n        test_dataset,\n        batch_size=test_bs,\n        shuffle=False,\n        num_workers=4\n    )\n\n    model = SEResNext50_32x4d(pretrained=\"imagenet\")\n    model.load_state_dict(torch.load(os.path.join(model_path)))\n    model.to(device)\n\n    predictions = Engine(model,device,test_loader).predict()\n    predictions = [tensor.detach().cpu().numpy() for tensor in predictions]\n    predictions = np.vstack((predictions)).ravel()\n    return predictions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(1)\ntrain(2)\ntrain(3)\ntrain(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p0 = predict(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df= pd.read_csv(\"../input/siim-isic-melanoma-classification/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"images_names = list(df.image_name.values)\nprint(len(images_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"image_path_name = os.listdir(\"../input/siim-isic-melanoma-classification/jpeg/train\")\nprint(len(image_path_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"image_path_pre = os.listdir(\"../input/siic-isic-224x224-images/train\")\nprint((image_path_pre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print((pd.Series(images_names).isin(pd.Series(image_path_pre))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_name = df.image_name.values.tolist()\nimage_name_path = [os.path.join(\"../input/siic-isic-224x224-images/train\", i+\".png\") for i in image_name]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_names_converted_of_df = [(image_name.replace) for i in image_name]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print((pd.Series(images_names).isin(pd.Series(image_path_pre))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}